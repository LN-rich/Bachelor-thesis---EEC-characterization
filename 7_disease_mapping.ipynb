{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mapping dieseased samples on top of healthy atlas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General\n",
    "import scipy as sci\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import logging\n",
    "import time\n",
    "import pickle\n",
    "from itertools import chain\n",
    "import h5py\n",
    "import scipy.sparse as sparse\n",
    "import anndata as ad\n",
    "import gc\n",
    "import scipy.stats as stats\n",
    "import torch\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib import rcParams\n",
    "from matplotlib.pyplot import rc_context\n",
    "from matplotlib import cm\n",
    "import seaborn as sb\n",
    "\n",
    "# Analysis\n",
    "import scanpy as sc\n",
    "import scanpy.external as sce\n",
    "import scvi\n",
    "\n",
    "import scarches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') #(action='once')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## setup matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings\n",
    "\n",
    "## Directory\n",
    "base_dir = '/mnt/hdd/Notebooks/Gut_project/'\n",
    "sc.settings.figdir = base_dir + 'Figures'\n",
    "sc.settings.cachedir = base_dir + 'Cache'\n",
    "\n",
    "## Scanpy settings\n",
    "sc.settings.verbosity = 3\n",
    "sc.logging.print_header()\n",
    "sc.logging.print_versions()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run utils.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mymap = load_RdOrYl_cmap_settings(transparent=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set paths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_model_dir_prefix = \"/mnt/hdd/data/Healthy/\"  # directory in which to store the reference model directory\n",
    "surgery_model_dir_prefix = (\n",
    "    \"/mnt/hdd/data/Disease\"  # directory in which to store the surgery model directory\n",
    ")\n",
    "path_reference_emb = (\n",
    "    \"/mnt/hdd/Notebooks/Gut_project/adata_markedDoublets_mergedPeaks_normalized_initialAnno_rmDoublets_integrated_imputed_annotated.h5ad\"  # path to reference embedding to be created\n",
    ")\n",
    "path_query_data = \"/mnt/hdd/data/Diseased/adata_markedDoublets_normalized_initialAnno_noimmune_scvi_wodblts.h5ad\"  # input test query data\n",
    "# don't change the following paths:\n",
    "ref_model_dir = \"/mnt/hdd/data/Healthy/Models/2024-07-31_Healthy_mdata_markedDoublets_normalized_initialAnno_rmDoublets_integrated_labelsInitialCellType_layers2_hidden512_latent50_scANVI\"  # don't change this\n",
    "surgery_model_dir = os.path.join(\n",
    "    surgery_model_dir_prefix, \"surgery_model\"\n",
    ")  # don't change this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_ref = sc.read_h5ad('/mnt/hdd/data/Healthy/adata_markedDoublets_normalized_initialAnno_noimmune_multivi_orig_wodblts_metadata.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#join covariates for scarches\n",
    "adata_ref.obs['covariates'] = adata_ref.obs['sample']\n",
    "adata_ref.obs['covariates'] = adata_ref.obs.apply(lambda row: '_'.join([row['sample'], row['kit']]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the scANVI model from the saved file\n",
    "model_path = f\"{ref_model_dir}\"\n",
    "model = scvi.model.SCANVI.load(model_path, adata_ref)\n",
    "\n",
    "# Extract the latent representation for the reference data\n",
    "latent_representation = model.get_latent_representation()\n",
    "\n",
    "# Create a new AnnData object for the latent representation\n",
    "adata_ref_latent = ad.AnnData(latent_representation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_ref_latent.obs = adata_ref.obs.loc[adata_ref.obs.index, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_ref_latent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_ref_latent.obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_query_unprep = sc.read_h5ad(path_query_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_query_unprep.X = sparse.csr_matrix(adata_query_unprep.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del adata_query_unprep.obsm\n",
    "del adata_query_unprep.varm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the data should have raw counts and not normalized counts in adata.X. Let’s do a quick check to see if we have integer data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_query_unprep.X[:10, :30].toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_ref.var.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del adata_ref\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the HLCA reference model requires ensemble IDs. Therefore, if your data includes ensembl IDs, we can proceed and use the standard scArches function to subset and pad our query AnnData. Make sure your adata_query_unprep.var.index contains the gene ids. If you instead only have gene names and no IDs for your query data, we will have to prepare your data manually (see below).\n",
    "\n",
    "The test data already has ensembl ids as index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_query_unprep.var.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_model_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_query = scarches.models.SCANVI.prepare_query_anndata(\n",
    "    adata=adata_query_unprep, reference_model=ref_model_dir, inplace=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your query adata will now have the same number of genes as the number of model input features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all columns in obs to strings\n",
    "adata_query.obs = adata_query.obs.applymap(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#join covariates for scarches\n",
    "adata_query.obs['covariates'] = adata_query.obs['sample']\n",
    "adata_query.obs['covariates'] = adata_query.obs.apply(lambda row: '_'.join([row['sample'], row['kit']]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#join covariates for scarches\n",
    "adata_ref_latent.obs['covariates'] = adata_ref_latent.obs['sample']\n",
    "adata_ref_latent.obs['covariates'] = adata_ref_latent.obs.apply(lambda row: '_'.join([row['sample'], row['kit']]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surgery_model = scarches.models.SCANVI.load_query_data(\n",
    "    adata_query,\n",
    "    ref_model_dir,\n",
    "    freeze_dropout=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surgery_model.registry_[\"setup_args\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are three setup arguments that were used for building the reference model, and that should be used for preparing scArches surgery as well: 1. batch_key: this key is used to specify from which batch your query dataset comes. The HLCA reference model was set up to retain variation between individuals, and so rather than treating each sample or individual as a separate batch, each dataset was considered one batch. We therefore recommend using the same logic for an HLCA query, and set an entire dataset to a single batch. If your data has further splits that could result in specific batch effects, split your data into separate batches accordingly (e.g. if part of your data was generated with 10X 3’, and the rest with 10X 5’). 2. labels_key: as the HLCA has a scANVI reference model, it used cell type labels as input for the training. These cell type labels were stored in a column named ‘scanvi_label’. We recommend not using cell type labels for surgery, and so advise to set this column to ‘unlabeled’ (see below). 3. unlabeled_category: this variable specifies how cells without label were named for this specific model. As you can see, they were in this case set to the string ‘unlabeled’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will furthermore set the cell type key to the unlabeled_category for all our cells, and recommend doing the same for any dataset mapped to the HLCA:\n",
    "\n",
    "adata_query.obs[\"scanvi_label\"] = \"unlabeled\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surgery_epochs = 500\n",
    "early_stopping_kwargs_surgery = {\n",
    "    \"early_stopping_monitor\": \"elbo_train\",\n",
    "    \"early_stopping_patience\": 10,\n",
    "    \"early_stopping_min_delta\": 0.001,\n",
    "    \"plan_kwargs\": {\"weight_decay\": 0.0},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surgery_model.train(max_epochs=surgery_epochs, **early_stopping_kwargs_surgery)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "Now that we have the updated model, we can calculate the low-dimensional representation or “embedding” of our query data. Importantly, this embedding is in the same space as the HLCA core/reference embedding that you loaded in the beginning of the script. Hence, we can combine the two embeddings afterwards (HLCA + your new data), and do joint clustering, UMAP embedding, label transfer etc.! The latent embedding will be stored in a new anndata under .X with the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_query_latent = sc.AnnData(surgery_model.get_latent_representation(adata_query))\n",
    "\n",
    "#Copy over .obs metadata from our query data:\n",
    "\n",
    "adata_query_latent.obs = adata_query.obs.loc[adata_query.obs.index, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our query embedding, we can combine it with the pre-existing reference embedding that we downloaded at the top of this notebook. Once we have that joint embedding, we can do all kinds of analyses on the combined reference and query, including clustering, visualization, and label transfer (see below).\n",
    "\n",
    "Before joining the reference and the query, let’s specify for the cells from each whether they came from the reference or the query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adata_query_latent.obs[\"ref_or_query\"] = \"query\"\n",
    "adata_ref_latent.obs[\"ref_or_query\"] = \"ref\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now combine the two embeddings to enable joint clustering etc. If you expect non-unique barcodes (.obs index), set index_unique to e.g. “_” (this will add a suffix to your barcodes to ensure we can keep apart reference and query barcodes) and batch_key to the obs column that you want to use as barcode suffix (e.g. “ref_or_query”)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_query_latent.write('adata_diseased_latent.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_ref.obsm[\"X_scarches_emb\"] = adata_ref_latent[\n",
    "    adata_ref.obs.index, :\n",
    "].X  # copy over scArches/reference-based embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_ref.write('adata_ref_latent.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_query_latent = sc.read_h5ad('adata_diseased_latent.h5ad') #start here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del adata_ref\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## concat to combined embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_emb = sc.concat(\n",
    "    (adata_ref_latent, adata_query_latent), join=\"outer\") #,index_unique=\"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cat in combined_emb.obs.columns:\n",
    "    if isinstance(combined_emb.obs[cat].values, pd.Categorical):\n",
    "        pass\n",
    "    elif pd.api.types.is_float_dtype(combined_emb.obs[cat]):\n",
    "        pass\n",
    "    else:\n",
    "        print(\n",
    "            f\"Setting obs column {cat} (not categorical neither float) to strings to prevent writing error.\"\n",
    "        )\n",
    "        combined_emb.obs[cat] = combined_emb.obs[cat].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_emb.obs.drop(['Internal ID'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_emb.write_h5ad(\"combined_embedding_diseased_healthy_scarches.h5ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_emb = sc.read_h5ad('combined_embedding_diseased_healthy_scarches.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_query_latent = combined_emb[combined_emb.obs['ref_or_query']=='query'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_query_latent.obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_query_latent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_ref_latent = combined_emb[combined_emb.obs['ref_or_query']=='ref'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get cell_type_annotation_lv1\n",
    "from anndata._io.specs import read_elem\n",
    "with h5py.File('adata_markedDoublets_mergedPeaks_normalized_initialAnno_rmDoublets_integrated_imputed_annotated.h5ad', 'r') as f:\n",
    "    # Read specific columns from `obs`\n",
    "    #sample_column = f['obs/sample'][:]\n",
    "    #n_counts_column = f['obs/n_counts'][:]\n",
    "    #https://github.com/scverse/anndata/issues/436:\n",
    "    #cell_types = read_elem(f[\"obs/celltype\"])\n",
    "    #umap = read_elem(f[\"obsm/X_umap\"])\n",
    "    anno_obs = read_elem(f[\"obs/cell_type_annotation_lv1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_ref_latent.obs['cell_type_annotation_lv1'] = anno_obs\n",
    "adata_ref_latent.obs['cell_type_annotation_lv1'] = adata_ref_latent.obs['cell_type_annotation_lv1'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_ref_latent.X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label transfer\n",
    "Next, we use a knn classifier to transfer the lables from the reference to the query. As the HLCA includes 5 levels of annotations (from coarse to fine), we will do the label transfer for every level of annotation. Note that some cell types don’t have annotations for higher levels, e.g. mast cells do not have level 4 or 5 annotations. For those cell types, we will “propagate” to the higher levels, i.e. you will see “3_Mast cells” in level 4 and 5 annotations. (Most cell types don’t have a level 5 annotation!) Therefore, all highest level annotations can be found under level 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_transformer = scarches.utils.knn.weighted_knn_trainer(\n",
    "    train_adata=adata_ref_latent,\n",
    "    train_adata_emb=\"X\",  # location of our joint embedding\n",
    "    n_neighbors=50,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let’s peform label transfer for the 5 levels of labels in the reference (“ann_level_1” to “ann_level_5”)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_query_latent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_ref_latent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_query_latent.obs['cell_type_annotation_lv1'] = adata_query_latent.obs['initial_cell_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_ref_latent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels, uncert = scarches.utils.knn.weighted_knn_transfer(\n",
    "    query_adata=adata_query_latent,\n",
    "    query_adata_emb=\"X\",  # location of our embedding, query_adata.X in this case\n",
    "    label_keys=\"cell_type_annotation_lv1\",  # (start of) obs column name(s) for which to transfer labels, if issue: make sure you did not already add the further steps to adata\n",
    "    knn_model=knn_transformer,\n",
    "    ref_adata_obs=adata_ref_latent.obs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the commands above, we labeled every cell from the query (labels dataframe). Moreover, for each query cell we get an uncertainty score that tells you how confidently the label was assigned to the cell (uncert dataframe). This uncertainty score is based on how consistent the reference labels were among the nearest neighbors of the query cell. High label transfer uncertainty can indicate a number of things: 1. The cell lies in between two cellular phenotypes, e.g. in the case of a continuous transition of one cell type into another. 2. The cell is of a cell type or subtype not present in the reference. For example, the HLCA does not include erythrocytes. Erythrocytes in a query dataset will therefore likely be labeled with high uncertainty. Similarly, disease samples might include disease-affected cell types that look different from the cells in a healthy reference. These also likely have high label transfer uncertainty. 3. The mapping did not successfully remove batch-effects in the query data from the embedding. Query cells do not mix with the reference in the joint embedding, complicating confident label transfer. To distinguish low-uncertainty from high-uncertainty transferred labels, we will set our high-uncertainty labels to “unknown” instead of giving them a cell type label. Cells with high uncertainty should be looked into in downstream analysis.\n",
    "\n",
    "We set the uncertainty threshold to 0.2, limiting the false positive rate to <0.5 (as per Sikkema et al., bioRxiv 2022). If you are dealing with data that you expect to look very different from your reference (e.g. mouse data or cell line data), you could consider setting this threshold higher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_emb.obs.drop(['cell_type_annotation_lv1_transferred_label_unfiltered', 'cell_type_annotation_lv1_transfer_uncert', 'cell_type_annotation_lv1_transferred_label'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uncertainty_threshold = 0.2 #in the HLCA it is 0.2\n",
    "\n",
    "#Let’s clean up the column names and add the transferred labels and matching uncertainties to our combined embedding (including both the query and the reference).\n",
    "\n",
    "labels.rename(\n",
    "    columns={\n",
    "        f\"{anno}\": f\"{anno}_transferred_label_unfiltered\"\n",
    "        for anno in ['cell_type_annotation_lv1']\n",
    "    },\n",
    "    inplace=True,\n",
    ")\n",
    "uncert.rename(\n",
    "    columns={\n",
    "        f\"{anno}\": f\"{anno}_transfer_uncert\"\n",
    "        for anno in ['cell_type_annotation_lv1']\n",
    "    },\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "combined_emb.obs = combined_emb.obs.join(labels)\n",
    "combined_emb.obs = combined_emb.obs.join(uncert)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uncert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_emb.obs.cell_type_annotation_lv1_transfer_uncert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now let’s generate a filtered label column for each label, setting labels transferred with uncertainty >0.2 to “Unknown”:\n",
    "uncertainty_threshold = 0.2 #in the HLCA it is 0.2\n",
    "\n",
    "for anno in ['cell_type_annotation_lv1']:\n",
    "    combined_emb.obs[f\"{anno}_transferred_label\"] = combined_emb.obs[\n",
    "        f\"{anno}_transferred_label_unfiltered\"\n",
    "    ].mask(\n",
    "        combined_emb.obs[f\"{anno}_transfer_uncert\"] > uncertainty_threshold,\n",
    "        \"Unknown\",\n",
    "    )\n",
    "\n",
    "#Let’s take a look at the percentage of cells set to “unknown” after our filtering:\n",
    "\n",
    "print(\n",
    "    f\"Percentage of unknown per level, with uncertainty_threshold={uncertainty_threshold}:\"\n",
    ")\n",
    "for anno in ['cell_type_annotation_lv1']:\n",
    "    print(\n",
    "        f\"{anno}: {np.round(sum(combined_emb.obs[f'{anno}_transferred_label'] =='Unknown')/adata_query_latent.n_obs*100,2)}%\"\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Important note! In some environments with older versions of scanpy/scvi-tools/scarches, there is a bug in the above code that we have not been able to properly pinpoint and fix. If you observe percentages of (close to) 100% of unknown above, you likely have the same bug and should update your packages. The transfered labels will then also be shuffled/random. (See also note at the top of this notebook)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of the joint reference and query embedding\n",
    "We will use a UMAP plot of our data to visually inspect the results of the mapping and label transfer. Calculating this will take a while on the HLCA (>.5M cells) + query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.neighbors(combined_emb, n_neighbors=30)\n",
    "sc.tl.umap(combined_emb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s first take a look at where our query cells are located in the umap. If they are completely separate from the reference, this could be a sign that something went wrong in the mapping. In our case, the query cells are largely mixing with or close to the reference cells in the UMAP.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(combined_emb, color=\"ref_or_query\", frameon=False,legend_fontsize=9, save='Umap_transfer_learned_superposed3.png', title= 'Joint embedding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_emb #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(combined_emb, color=metadata+[\"ref_or_query\"], frameon=False,legend_fontsize=8.5, ncols = 3, wspace = 0.9,save='Umap_transfer_learned_superposed_metadata.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(\n",
    "    combined_emb,\n",
    "    color=marker_genes,\n",
    "    #vmax=\"p99\",\n",
    "    cmap = mymap,\n",
    "    layer = 'log_dca_counts',\n",
    "    #wspace=0.7,\n",
    "    ncols=4,\n",
    "    save = 'umap_markers_transfered_embedding_joint_imputed.png'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### metadata actualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## add metadata\n",
    "metadata_df =read_excel_metadata(f'/mnt/hdd/data/metadata_mouse_gut.xlsx')\n",
    "# Ensure folder name is the index in metadata for easier access\n",
    "metadata_df.drop(metadata_df[metadata_df['kit'] == 'Multiome_ATAC_v1'].index, inplace=True)\n",
    "#metadata_df.drop(metadata_df[metadata_df['condition'].isin(['Ctr','Ctr/WT'])].index, inplace=True)\n",
    "metadata_df.set_index('folder name', inplace=True)\n",
    "metadata_df.drop(['Sample Pooling - confounded with Project?','date','Project Name','Link_id','sample name','Cell Count [cells/µl]','Viable Cells [%]','Lib. Concentration [ng/µl]','Lib. Molarity [nM]','Average Lib. Size [bp]','cDNA Cycles','Lib. Cycles','10x Sample Index','Sequencing Depth [reads/cell]','exclusion, reason'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to update adata.obs with metadata using a lambda function\n",
    "for col in metadata_df.columns:\n",
    "    try:\n",
    "        combined_emb.obs[col] = combined_emb.obs['sample'].apply(lambda x: metadata_df.at[x, col])\n",
    "    except KeyError as err:\n",
    "        print(f'no such key: {err} in col {col}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### label transfer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let’s take a look at the label transfer uncertainties per level. Regions with high uncertainty can highlight interesting cell types/states, not present in the reference. Note that uncertainties will get higher, the more detailed we go. Note that as we only used very few cells in the query here, they are more difficult to see in the joint embedding.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let’s take a look at the transferred labels, at every level. Note that the color for “Unknown” switches per plot, and that all cells from the reference are set to NA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(\n",
    "    combined_emb,\n",
    "    color=[f\"{anno}_transfer_uncert\"],\n",
    "    na_color=\"grey\",\n",
    "    ncols=2,\n",
    "    size=2,\n",
    "    wspace=1,\n",
    "    save='Umap_transfer_learned_superposed_label_uncertainty.png'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_key = f\"{anno}_transferred_label_unfiltered\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_emb.obs[annotation_key] = combined_emb.obs[annotation_key].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_emb.obs[annotation_key] = combined_emb.obs[annotation_key].cat.reorder_categories(['ISC', 'TA', 'TA (prox.))', 'early Enterocyte', 'Enterocyte', \n",
    "'Tuft prog.', 'Tuft prog. 2', 'Tuft', \n",
    "'Goblet/EEC prog. (early)', 'EEC prog. (mid)', 'EEC prog. (late/Peptide)', 'EEC (Peptide/immature)', 'X-cell (Ghrl+)',  'K-cell (Gip+)', 'L/I-cell (Glp1+/Cck+)', 'D-cell (Sst+)',\n",
    "'EC prog. (late)', 'EC (immature)', 'EC (mature)','EC 2', \n",
    " 'Goblet prog. (late)', 'Goblet',  'Paneth prog.', 'Paneth', 'unknown0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_emb.uns[f'{annotation_key}' + '_colors'] = ['#d0d0d0',  # ISC\n",
    " '#eebcbc',  # TA\n",
    " '#fee0d2',  # TA prox\n",
    " '#c67a84',  # early Enterocyte\n",
    " '#bb4353',  # Enterocyte\n",
    " '#eca4d0',  # Tuft prog.\n",
    " '#df65b0',  # Tuft prog. 2\n",
    " '#e7298a',  # Tuft\n",
    " '#e1f3bf',  # Goblet/EEC prog.\n",
    " '#d9edf7',  # EEC prog\n",
    " '#85c6e6',  # EEC prog. (late/Peptide)\n",
    " '#46a8d9',  # EEC (peptide/immature)\n",
    " '#339a98',  # X-cell (Ghrl+)\n",
    " '#368cbf',  # K-cell (Gip+)\n",
    " '#5a72dd',  # L/I-cell (Glp1+/Cck+)\n",
    " '#243dae',  # D-cell (Sst+)\n",
    " '#d0d1e6',  # EC prog.\n",
    " '#aa9dce',  # EC (imm.)\n",
    " '#594495',  # EC (mature)\n",
    " '#725dae',  # EC 2\n",
    " '#fec44f',  # Goblet prog.\n",
    " '#dd894e',  # Goblet\n",
    " '#7BB98F',  # Paneth prog.\n",
    " '#238b45',  # Paneth\n",
    " '#ac9470'   # unknown0\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(\n",
    "    combined_emb,\n",
    "    color=[f\"{anno}_transferred_label_unfiltered\"],\n",
    "    na_color=\"grey\",\n",
    "    ncols=2,\n",
    "    size=2,\n",
    "    wspace=1,\n",
    "    legend_fontsize =9,\n",
    "    save='Umap_transfer_learned_superposed_transferred_labels.png',\n",
    "    title = 'Transfered cell types on diseased query'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del adata_ref_latent\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## explore query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_query_final = (\n",
    "    adata_query_unprep.copy()\n",
    ")  # copy the original query adata, including gene counts\n",
    "\n",
    "adata_query_final.obsm[\"X_scarches_emb\"] = adata_query_latent[\n",
    "    adata_query_final.obs.index, :\n",
    "].X  # copy over scArches/reference-based embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_emb = combined_emb[combined_emb.obs[\"ref_or_query\"]=='query'] #because of barcode overlapping -.-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in combined_emb.obs.columns:\n",
    "    if col.startswith(\"cell_type\") and \"transfer\" in col:\n",
    "        print(col)\n",
    "        adata_query_final.obs[col] = combined_emb.obs.loc[\n",
    "            adata_query_final.obs.index, col\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ctanno in ['cell_type_annotation_lv1_transferred_label_unfiltered','cell_type_annotation_lv1_transfer_uncert','cell_type_annotation_lv1_transferred_label']:\n",
    "    adata_query_final.obs[ctanno] = adata_query_final.obs[ctanno].astype(str)\n",
    "adata_query_final.write('adata_query_final.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_query_final = sc.read_h5ad('adata_query_final.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del adata_query_unprep\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# add dca imputed counts\n",
    "from anndata._io.specs import read_elem\n",
    "with h5py.File('/mnt/hdd/data/Diseased/Dbtl_detected_velocyto_scran_diseased_sct_imputed_subsetted.h5ad', 'r') as f:\n",
    "    # Read specific columns from `obs`\n",
    "    #sample_column = f['obs/sample'][:]\n",
    "    #n_counts_column = f['obs/n_counts'][:]\n",
    "    #https://github.com/scverse/anndata/issues/436:\n",
    "    #cell_types = read_elem(f[\"obs/celltype\"])\n",
    "    #umap = read_elem(f[\"obsm/X_umap\"])\n",
    "    dca = read_elem(f[\"layers/log_dca_counts\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata2 = sc.read_h5ad('/mnt/hdd/data/Diseased/Dbtl_detected_velocyto_scran_diseased_sct_imputed_subsetted.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_imputed = [name for name in adata2.var_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dca = adata2.layers['log_dca_counts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del adata2\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_query_final = adata_query_final[:, vars_imputed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_query_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_query_final.layers['log_dca_counts']= dca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del dca\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## add metadata\n",
    "metadata_df =read_excel_metadata(f'/mnt/hdd/data/metadata_mouse_gut.xlsx')\n",
    "# Ensure folder name is the index in metadata for easier access\n",
    "metadata_df.drop(metadata_df[metadata_df['kit'] == 'Multiome_ATAC_v1'].index, inplace=True)\n",
    "metadata_df.drop(metadata_df[metadata_df['condition'].isin(['Ctr','Ctr/WT'])].index, inplace=True)\n",
    "metadata_df.set_index('folder name', inplace=True)\n",
    "metadata_df.drop(['Sample Pooling - confounded with Project?','date','Project Name','Link_id','sample name','Cell Count [cells/µl]','Viable Cells [%]','Lib. Concentration [ng/µl]','Lib. Molarity [nM]','Average Lib. Size [bp]','cDNA Cycles','Lib. Cycles','10x Sample Index','Sequencing Depth [reads/cell]','exclusion, reason'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to update adata.obs with metadata using a lambda function\n",
    "for col in metadata_df.columns:\n",
    "    try:\n",
    "        adata_query_final.obs[col] = adata_query_final.obs['sample'].apply(lambda x: metadata_df.at[x, col])\n",
    "    except KeyError as err:\n",
    "        print(f'no such key: {err} in col {col}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_query_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## add phase to diseased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cc_genes, s_genes_regev, g2m_genes_regev, cc_genes_regev, cc_genes_macosko, s_genes_macosko, g2m_genes_macosko, m_genes_macosko, mg1_genes_macosko, g1s_genes_macosko = load_cell_cycle_genes(adata_query_final, genome='mus_musculus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.tl.score_genes_cell_cycle(adata_query_final, s_genes=s_genes_regev, g2m_genes=g2m_genes_regev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_query_final.obs['proliferation'] = list(adata_query_final.obs['phase'].isin(['G2M','S']))\n",
    "adata_query_final.obs['proliferation'][adata_query_final.obs['proliferation']==True] = 'Cycling'\n",
    "adata_query_final.obs['proliferation'][adata_query_final.obs['proliferation']==False] = 'Non-Cycling'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### add diseased cell cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_emb.obs['phase'][combined_emb.obs['ref_or_query']=='query'] = adata_query_final.obs['phase'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### covariates combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.tl.pca(combined_emb)\n",
    "\n",
    "n_pcs = 49\n",
    "\n",
    "#specifiy covariates we want to check (we will quantify their correlation with the 1st 50 PCs, to see how much variance they can each explain):\n",
    "\n",
    "covariates = [\n",
    "    \"sample\",\n",
    "'doublet_calls', 'final_doublets', 'final_doublets_cat', 'phase', 'proliferation', 'initial_cell_type','Project','sequencing','condition','kit','line','strain','enriched','enrichment proportion','diet','Index Type','sequencing machine','cell_type_annotation_lv1_transferred_label_unfiltered'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create shuffled assignment of single cell platform (and processing site if included), to compare actual variance explained to variance explained expected by random. We will assign all cells of the same sample to the same value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "include_processing_site =True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create shuffled version of single cell platform, and of Processing_site:\n",
    "if include_processing_site:\n",
    "    sample_to_scplatform = combined_emb.obs.groupby(\"sample\").agg(\n",
    "        {\"Project\": \"first\", \"sequencing machine\": \"first\"}\n",
    "    )\n",
    "else:\n",
    "    sample_to_scplatform = combined_emb.obs.groupby(\"sample\").agg(\n",
    "        {\"Project\": \"first\"}\n",
    "    )\n",
    "for i in range(10):\n",
    "    np.random.shuffle(sample_to_scplatform.Project)\n",
    "    combined_emb.obs[\"Project_shuffled_\" + str(i)] = combined_emb.obs[\"sample\"].map(\n",
    "        dict(\n",
    "            zip(\n",
    "                sample_to_scplatform.index,\n",
    "                sample_to_scplatform.Project,\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    covariates.append(\"Project_shuffled_\" + str(i))\n",
    "    if include_processing_site:\n",
    "        np.random.shuffle(sample_to_scplatform['sequencing machine'])\n",
    "        combined_emb.obs[\"sequencing machine_shuffled_\" + str(i)] = combined_emb.obs[\"sample\"].map(\n",
    "            dict(zip(sample_to_scplatform.index, sample_to_scplatform['sequencing machine']))\n",
    "        )\n",
    "        covariates.append(\"sequencing machine_shuffled_\" + str(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now check for every covariate, for every PC how much variance among the cells' PC scores the covariate can explain. Add this variance explained per PC up across PCs for every covariate. This will give us the total amount of variance explained per covariate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def check_if_nan(value):\n",
    "    \"\"\"return Boolean version of value that is True if value is\n",
    "    some type of NaN (e.g. np.nan, None, \"nan\" etc). \n",
    "    Example use:\n",
    "    none_entries = subadata.obs.applymap(check_if_nan)\n",
    "    subadata.obs = subadata.obs.mask(none_entries.values)\n",
    "    \"\"\"\n",
    "    if value == \"nan\":\n",
    "        return True\n",
    "    elif value == None:\n",
    "        return True\n",
    "    if isinstance(value, float):\n",
    "        if np.isnan(value):\n",
    "            return True\n",
    "    if value == \"ND\":\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_explained = pd.DataFrame(index=range(n_pcs), columns=covariates + [\"overall\"])\n",
    "for pc in range(n_pcs):\n",
    "    y_true_unfiltered = combined_emb.obsm[\"X_pca\"][:, pc]\n",
    "    var_explained.loc[pc, \"overall\"] = np.var(y_true_unfiltered)\n",
    "    for cov in covariates:\n",
    "        x = combined_emb.obs[cov].values.copy()\n",
    "        x_nans = np.vectorize(check_if_nan)(x)\n",
    "        x = x[~x_nans]\n",
    "        if len(x) != 0:\n",
    "            y_true = y_true_unfiltered[~x_nans].reshape(-1, 1)\n",
    "            if x.dtype in [\"float32\", \"float\", \"float64\"]:\n",
    "                x = x.reshape(-1, 1)\n",
    "            else:\n",
    "                if len(set(x)) == 1:\n",
    "                    var_explained.loc[pc, cov] = np.nan\n",
    "                    continue\n",
    "                x = pd.get_dummies(x)\n",
    "            x.columns = x.columns.astype(str)\n",
    "            lrf = LinearRegression(fit_intercept=True).fit(\n",
    "                x,\n",
    "                y_true,\n",
    "            )\n",
    "            y_pred = lrf.predict(x)\n",
    "            var_explained.loc[pc, cov] = np.var(y_pred)\n",
    "total_variance_explained = np.sum(var_explained, axis=0).sort_values(ascending=False)\n",
    "total_variance_explained_fractions = (\n",
    "    total_variance_explained / total_variance_explained[\"overall\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the same for the shuffled covariates. Calculate mean over shuffling instances, add as one value to clean fractions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_variance_explained_clean = total_variance_explained_fractions[\n",
    "    [\n",
    "        x\n",
    "        for x in total_variance_explained_fractions.index\n",
    "        if not x.startswith(\"sequencing machine_shuffled\")\n",
    "        and not x.startswith(\"Project_shuffled\")\n",
    "    ]\n",
    "]\n",
    "total_variance_explained_clean[\"Project_shuffled\"] = np.mean(\n",
    "    total_variance_explained_fractions[\n",
    "        [\n",
    "            x\n",
    "            for x in total_variance_explained_fractions.index\n",
    "            if x.startswith(\"Project_\")\n",
    "        ]\n",
    "    ]\n",
    ")\n",
    "stdev_Project_shuffled = np.std(\n",
    "    total_variance_explained_fractions[\n",
    "        [\n",
    "            x\n",
    "            for x in total_variance_explained_fractions.index\n",
    "            if x.startswith(\"Project_\")\n",
    "        ]\n",
    "    ]\n",
    ")\n",
    "if include_processing_site:\n",
    "    total_variance_explained_clean[\"sequencing machine_shuffled\"] = np.mean(\n",
    "        total_variance_explained_fractions[\n",
    "            [\n",
    "                x\n",
    "                for x in total_variance_explained_fractions.index\n",
    "                if x.startswith(\"sequencing machine_shuffled\")\n",
    "            ]\n",
    "        ]\n",
    "    )\n",
    "    stdev_processing_site_shuffled = np.std(\n",
    "        total_variance_explained_fractions[\n",
    "            [\n",
    "                x\n",
    "                for x in total_variance_explained_fractions.index\n",
    "                if x.startswith(\"sequencing machine_shuffled\")\n",
    "            ]\n",
    "        ]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_variance_explained_clean.sort_values(ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "plt.bar(\n",
    "    total_variance_explained_clean[::-1].index,\n",
    "    total_variance_explained_clean[::-1].values,\n",
    ")\n",
    "plt.title(\n",
    "    f\"covariate correlation with first 50 PCs of healthy and diseased samples combined\",\n",
    "    fontsize=14,\n",
    ")  # \\n({dominant_type})\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## main covariates diseased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.tl.pca(adata_query_final)\n",
    "\n",
    "n_pcs = 50\n",
    "\n",
    "#specifiy covariates we want to check (we will quantify their correlation with the 1st 50 PCs, to see how much variance they can each explain):\n",
    "\n",
    "covariates = [\n",
    "    \"sample\",\n",
    "'doublet_calls', 'final_doublets', 'final_doublets_cat', 'phase', 'proliferation', 'initial_cell_type','Project','sequencing','condition','kit','line','strain','enriched','enrichment proportion','diet','Index Type','sequencing machine','cell_type_annotation_lv1_transferred_label_unfiltered'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create shuffled assignment of single cell platform (and processing site if included), to compare actual variance explained to variance explained expected by random. We will assign all cells of the same sample to the same value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "include_processing_site =True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create shuffled version of single cell platform, and of Processing_site:\n",
    "if include_processing_site:\n",
    "    sample_to_scplatform = adata_query_final.obs.groupby(\"sample\").agg(\n",
    "        {\"Project\": \"first\", \"sequencing machine\": \"first\"}\n",
    "    )\n",
    "else:\n",
    "    sample_to_scplatform = adata_query_final.obs.groupby(\"sample\").agg(\n",
    "        {\"Project\": \"first\"}\n",
    "    )\n",
    "for i in range(10):\n",
    "    np.random.shuffle(sample_to_scplatform.Project)\n",
    "    adata_query_final.obs[\"Project_shuffled_\" + str(i)] = adata_query_final.obs[\"sample\"].map(\n",
    "        dict(\n",
    "            zip(\n",
    "                sample_to_scplatform.index,\n",
    "                sample_to_scplatform.Project,\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    covariates.append(\"Project_shuffled_\" + str(i))\n",
    "    if include_processing_site:\n",
    "        np.random.shuffle(sample_to_scplatform['sequencing machine'])\n",
    "        adata_query_final.obs[\"sequencing machine_shuffled_\" + str(i)] = adata_query_final.obs[\"sample\"].map(\n",
    "            dict(zip(sample_to_scplatform.index, sample_to_scplatform['sequencing machine']))\n",
    "        )\n",
    "        covariates.append(\"sequencing machine_shuffled_\" + str(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now check for every covariate, for every PC how much variance among the cells' PC scores the covariate can explain. Add this variance explained per PC up across PCs for every covariate. This will give us the total amount of variance explained per covariate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def check_if_nan(value):\n",
    "    \"\"\"return Boolean version of value that is True if value is\n",
    "    some type of NaN (e.g. np.nan, None, \"nan\" etc). \n",
    "    Example use:\n",
    "    none_entries = subadata.obs.applymap(check_if_nan)\n",
    "    subadata.obs = subadata.obs.mask(none_entries.values)\n",
    "    \"\"\"\n",
    "    if value == \"nan\":\n",
    "        return True\n",
    "    elif value == None:\n",
    "        return True\n",
    "    if isinstance(value, float):\n",
    "        if np.isnan(value):\n",
    "            return True\n",
    "    if value == \"ND\":\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_explained = pd.DataFrame(index=range(n_pcs), columns=covariates + [\"overall\"])\n",
    "for pc in range(n_pcs):\n",
    "    y_true_unfiltered = adata_query_final.obsm[\"X_pca\"][:, pc]\n",
    "    var_explained.loc[pc, \"overall\"] = np.var(y_true_unfiltered)\n",
    "    for cov in covariates:\n",
    "        x = adata_query_final.obs[cov].values.copy()\n",
    "        x_nans = np.vectorize(check_if_nan)(x)\n",
    "        x = x[~x_nans]\n",
    "        if len(x) != 0:\n",
    "            y_true = y_true_unfiltered[~x_nans].reshape(-1, 1)\n",
    "            if x.dtype in [\"float32\", \"float\", \"float64\"]:\n",
    "                x = x.reshape(-1, 1)\n",
    "            else:\n",
    "                if len(set(x)) == 1:\n",
    "                    var_explained.loc[pc, cov] = np.nan\n",
    "                    continue\n",
    "                x = pd.get_dummies(x)\n",
    "            x.columns = x.columns.astype(str)\n",
    "            lrf = LinearRegression(fit_intercept=True).fit(\n",
    "                x,\n",
    "                y_true,\n",
    "            )\n",
    "            y_pred = lrf.predict(x)\n",
    "            var_explained.loc[pc, cov] = np.var(y_pred)\n",
    "total_variance_explained = np.sum(var_explained, axis=0).sort_values(ascending=False)\n",
    "total_variance_explained_fractions = (\n",
    "    total_variance_explained / total_variance_explained[\"overall\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the same for the shuffled covariates. Calculate mean over shuffling instances, add as one value to clean fractions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_variance_explained_clean = total_variance_explained_fractions[\n",
    "    [\n",
    "        x\n",
    "        for x in total_variance_explained_fractions.index\n",
    "        if not x.startswith(\"sequencing machine_shuffled\")\n",
    "        and not x.startswith(\"Project_shuffled\")\n",
    "    ]\n",
    "]\n",
    "total_variance_explained_clean[\"Project_shuffled\"] = np.mean(\n",
    "    total_variance_explained_fractions[\n",
    "        [\n",
    "            x\n",
    "            for x in total_variance_explained_fractions.index\n",
    "            if x.startswith(\"Project_\")\n",
    "        ]\n",
    "    ]\n",
    ")\n",
    "stdev_Project_shuffled = np.std(\n",
    "    total_variance_explained_fractions[\n",
    "        [\n",
    "            x\n",
    "            for x in total_variance_explained_fractions.index\n",
    "            if x.startswith(\"Project_\")\n",
    "        ]\n",
    "    ]\n",
    ")\n",
    "if include_processing_site:\n",
    "    total_variance_explained_clean[\"sequencing machine_shuffled\"] = np.mean(\n",
    "        total_variance_explained_fractions[\n",
    "            [\n",
    "                x\n",
    "                for x in total_variance_explained_fractions.index\n",
    "                if x.startswith(\"sequencing machine_shuffled\")\n",
    "            ]\n",
    "        ]\n",
    "    )\n",
    "    stdev_processing_site_shuffled = np.std(\n",
    "        total_variance_explained_fractions[\n",
    "            [\n",
    "                x\n",
    "                for x in total_variance_explained_fractions.index\n",
    "                if x.startswith(\"sequencing machine_shuffled\")\n",
    "            ]\n",
    "        ]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_variance_explained_clean.sort_values(ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "plt.bar(\n",
    "    total_variance_explained_clean[::-1].index,\n",
    "    total_variance_explained_clean[::-1].values,\n",
    ")\n",
    "plt.title(\n",
    "    f\"covariate correlation with first 50 PCs of diseased samples\",\n",
    "    fontsize=14,\n",
    ")  # \\n({dominant_type})\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot query only with covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.neighbors(adata_query_final, use_rep=\"X_scarches_emb\")\n",
    "sc.tl.umap(adata_query_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anno = 'cell_type_annotation_lv1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_key = f\"{anno}_transferred_label\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_query_final.obs[annotation_key].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_query_final.obs[annotation_key] = adata_query_final.obs[annotation_key].cat.reorder_categories(['ISC', 'TA', 'TA (prox.))', 'early Enterocyte', 'Enterocyte', \n",
    "'Tuft prog.', 'Tuft prog. 2', 'Tuft', \n",
    "'Goblet/EEC prog. (early)', 'EEC prog. (mid)', 'EEC prog. (late/Peptide)', 'EEC (Peptide/immature)', 'X-cell (Ghrl+)',  'K-cell (Gip+)', 'L/I-cell (Glp1+/Cck+)', 'D-cell (Sst+)',\n",
    "'EC prog. (late)', 'EC (immature)', 'EC (mature)','EC 2', \n",
    " 'Goblet prog. (late)', 'Goblet',  'Paneth prog.', 'Paneth', 'unknown0','Unknown'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_query_final.uns[f'{annotation_key}' + '_colors'] = ['#d0d0d0',  # ISC\n",
    " '#eebcbc',  # TA\n",
    " '#fee0d2',  # TA prox\n",
    " '#c67a84',  # early Enterocyte\n",
    " '#bb4353',  # Enterocyte\n",
    " '#eca4d0',  # Tuft prog.\n",
    " '#df65b0',  # Tuft prog. 2\n",
    " '#e7298a',  # Tuft\n",
    " '#e1f3bf',  # Goblet/EEC prog.\n",
    " '#d9edf7',  # EEC prog\n",
    " '#85c6e6',  # EEC prog. (late/Peptide)\n",
    " '#46a8d9',  # EEC (peptide/immature)\n",
    " '#339a98',  # X-cell (Ghrl+)\n",
    " '#368cbf',  # K-cell (Gip+)\n",
    " '#5a72dd',  # L/I-cell (Glp1+/Cck+)\n",
    " '#243dae',  # D-cell (Sst+)\n",
    " '#d0d1e6',  # EC prog.\n",
    " '#aa9dce',  # EC (imm.)\n",
    " '#594495',  # EC (mature)\n",
    " '#725dae',  # EC 2\n",
    " '#fec44f',  # Goblet prog.\n",
    " '#dd894e',  # Goblet\n",
    " '#7BB98F',  # Paneth prog.\n",
    " '#238b45',  # Paneth\n",
    " '#ac9470',   # unknown0\n",
    " '#808080' #Unknown \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_key = f\"{anno}_transferred_label_unfiltered\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_query_final.obs[annotation_key] = adata_query_final.obs[annotation_key].cat.reorder_categories(['ISC', 'TA', 'TA (prox.))', 'early Enterocyte', 'Enterocyte', \n",
    "'Tuft prog.', 'Tuft prog. 2', 'Tuft', \n",
    "'Goblet/EEC prog. (early)', 'EEC prog. (mid)', 'EEC prog. (late/Peptide)', 'EEC (Peptide/immature)', 'X-cell (Ghrl+)',  'K-cell (Gip+)', 'L/I-cell (Glp1+/Cck+)', 'D-cell (Sst+)',\n",
    "'EC prog. (late)', 'EC (immature)', 'EC (mature)','EC 2', \n",
    " 'Goblet prog. (late)', 'Goblet',  'Paneth prog.', 'Paneth', 'unknown0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_query_final.uns[f'{annotation_key}' + '_colors'] = ['#d0d0d0',  # ISC\n",
    " '#eebcbc',  # TA\n",
    " '#fee0d2',  # TA prox\n",
    " '#c67a84',  # early Enterocyte\n",
    " '#bb4353',  # Enterocyte\n",
    " '#eca4d0',  # Tuft prog.\n",
    " '#df65b0',  # Tuft prog. 2\n",
    " '#e7298a',  # Tuft\n",
    " '#e1f3bf',  # Goblet/EEC prog.\n",
    " '#d9edf7',  # EEC prog\n",
    " '#85c6e6',  # EEC prog. (late/Peptide)\n",
    " '#46a8d9',  # EEC (peptide/immature)\n",
    " '#339a98',  # X-cell (Ghrl+)\n",
    " '#368cbf',  # K-cell (Gip+)\n",
    " '#5a72dd',  # L/I-cell (Glp1+/Cck+)\n",
    " '#243dae',  # D-cell (Sst+)\n",
    " '#d0d1e6',  # EC prog.\n",
    " '#aa9dce',  # EC (imm.)\n",
    " '#594495',  # EC (mature)\n",
    " '#725dae',  # EC 2\n",
    " '#fec44f',  # Goblet prog.\n",
    " '#dd894e',  # Goblet\n",
    " '#7BB98F',  # Paneth prog.\n",
    " '#238b45',  # Paneth\n",
    " '#ac9470'   # unknown0\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ctanno in ['cell_type_annotation_lv1_transferred_label_unfiltered','cell_type_annotation_lv1_transferred_label']:\n",
    "    adata_query_final.obs[ctanno] = adata_query_final.obs[ctanno].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_query_final.obs['cell_type_annotation_lv1_transfer_uncert'] = adata_query_final.obs['cell_type_annotation_lv1_transfer_uncert'].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(\n",
    "    adata_query_final,\n",
    "    color=[\n",
    "        f\"{anno}_transferred_label_unfiltered\",\n",
    "        f\"{anno}_transferred_label\",\n",
    "        f\"{anno}_transfer_uncert\",\n",
    "    ],\n",
    "    wspace=0.65,\n",
    "    cmap = mymap,\n",
    "    ncols=2,\n",
    "    legend_fontsize =9,\n",
    "    save='Umap_transfer_learned_superposed_transferred_labels2.png',\n",
    "    title = ['Transfered cell types on diseased query unfiltered','Transfered cell types on diseased query','Transfered cell types uncertainty']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marker_genes = ['Lgr5','Olfm4','Dmbt1','Arg2','Sis','Dclk1','Sox4','Pou2f3','Muc2','Dll1','Ccl25','Lyz1','Neurog3','Neurod1','Arx','Pax4','Spdef','Lmx1a','Reg4','Isl1','Sst','Gcg','Cck','Gip','Ghrl','Sct','Fev','Lbh', 'Rnase4','Ctse', 'Slc12a8','Reg1','Slc2a2','Ada', 'Golm1', 'Tff2', 'Muc1', 'Dmbt1', 'Insr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(\n",
    "    adata_query_final,\n",
    "    color=marker_genes,\n",
    "    #vmax=\"p99\",\n",
    "    cmap = mymap,\n",
    "    layer = 'log_dca_counts',\n",
    "    #wspace=0.7,\n",
    "    ncols=4,\n",
    "    save = 'umap_markers_transfered_embedding_diseased_imputed.png'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = ['pretty name','Project','kit','enriched','diet','condition','line','strain', 'phase']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(\n",
    "    adata_query_final,\n",
    "    color=metadata,\n",
    "    #vmax=\"p99\",\n",
    "    cmap = mymap,\n",
    "    wspace=0.75,\n",
    "    ncols=2,\n",
    "    legend_fontsize=9,\n",
    "    save = 'umap_metadata_transfered_embedding_diseased.png'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_query_final.obs.drop([\"modality (confounded with 'sequencing'\", 'Internal ID', 'SeqID', 'target cell number', 'Read Length', '_scvi_batch', '_scvi_labels', 'leiden_2', 'leiden_3', 'leiden_sub1','sample number Minas'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_query_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_query_final.write('adata_diseased_integrated_annotated.h5ad')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scUV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
